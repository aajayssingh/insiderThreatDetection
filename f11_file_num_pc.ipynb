{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from helper import pickle_store, pickle_restore\n",
    "import dateutil\n",
    "from adem import *\n",
    "from collections import Counter \n",
    "\n",
    "\n",
    "# #fetch all rawdata and save as pickle format for speed.\n",
    "# dev_raw_df = pd.read_csv(\"r4.2/device.csv\") # 2629979 rows, 11 columns\n",
    "\n",
    "# # Select small data till 1 April\n",
    "# pickle_store(\"dev_rawdf_file\", dev_raw_df) #raw means not indexed by Timeindex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_raw_df = pickle_restore(\"pickle/file_rawdf_file\")\n",
    "\n",
    "# dev_raw_df = pickle_restore(\"dev_rawdf_file\")\n",
    "\n",
    "dev_act_feature_df=file_raw_df[['user', 'date', 'pc']] #ONLY CHANGE iS THIS wrt device_fem\n",
    "\n",
    "\n",
    "dev_act_feature_df['date'] = pd.to_datetime(dev_act_feature_df['date'])\n",
    "mask = (dev_act_feature_df['date'] <= end_d) & (dev_act_feature_df['date'] >= start_d)\n",
    "# mask = dev_act_feature_df['date'] <= end_d\n",
    "dev_act_feature_df = dev_act_feature_df.loc[mask]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#create a copy of orig df so that I can separately process for ubp pbp and cbp\n",
    "dev_act_feature_cmnty_df = dev_act_feature_df.copy()\n",
    "dev_act_feature_peer_df = dev_act_feature_df.copy()\n",
    "\n",
    "# 1. in email_freq_feature_df add community and peer column with id as values.\n",
    "usr_cmnty_map = pickle_restore(\"pickle/community_louvian_file\")\n",
    "dev_act_feature_cmnty_df['cmnty']=dev_act_feature_cmnty_df.apply(lambda row: usr_cmnty_map[row.user], axis=1)\n",
    "\n",
    "usr_peer_map = pickle_restore(\"pickle/eid_role_map_file\")\n",
    "dev_act_feature_peer_df['peer']=dev_act_feature_peer_df.apply(lambda row: usr_peer_map[row.user], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also NOTE that unlike emails I have converted the dates to datetime format. \n",
    "# Convert date back to string format\n",
    "dev_act_feature_df['date']=dev_act_feature_df['date'].astype(str)\n",
    "dev_act_feature_cmnty_df['date']=dev_act_feature_cmnty_df['date'].astype(str)\n",
    "dev_act_feature_peer_df['date']=dev_act_feature_peer_df['date'].astype(str)\n",
    "\n",
    "# dev_act_feature_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now data is ready to generate prep_dic using groupby, UBP. Feature = num_activity\n",
    "def prep_ubp_dic(df):\n",
    "    #convert date column of srt type to Timestamp type.\n",
    "    df['date'] = df['date'].apply(dateutil.parser.parse, dayfirst=False) #NOTE converts day to day first year-dd-mm\n",
    "    #now convert date column of Timestamptype to only date values and remove hr:mm:ss\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    #creates user, date wise groups and each internal group is a dataframe.\n",
    "    # grp=tmp_email_freq_feature_df.groupby(['user', 'date'])\n",
    "\n",
    "    # create user, date wise groups and count unique dates then add a separate column for the counts\n",
    "    df=df.groupby(['user', 'date']).pc.agg('nunique').to_frame('num_pc').reset_index()\n",
    "\n",
    "    #groupby user now To populate a dictionary for each user.\n",
    "    grp=df.groupby(['user'])\n",
    "\n",
    "    email_freq_feature_dic={} #user:df with feature value\n",
    "    #iterating groups\n",
    "    for name, group in grp:\n",
    "        # print (name)\n",
    "        # print (group)\n",
    "        email_freq_feature_dic[name]=group\n",
    "        # ldf = group.groupby(['date'], as_index=False)['cntr'].size()\n",
    "\n",
    "    return email_freq_feature_dic\n",
    "\n",
    "\n",
    "def prep_cbp_dic(df):\n",
    "    #convert date column of srt type to Timestamp type.\n",
    "    df['date'] = df['date'].apply(dateutil.parser.parse, dayfirst=False)\n",
    "    #now convert date column of Timestamptype to only date values and remove hr:mm:ss\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    # create user, date wise groups and count unique dates then add a separate column for the counts\n",
    "    df=df.groupby(['cmnty', 'date']).pc.agg('nunique').to_frame('num_pc').reset_index()\n",
    "\n",
    "    cmnty_len = Counter(usr_cmnty_map.values())\n",
    "    #make values of email freq avg of community\n",
    "    df['num_pc'] = df.apply( lambda x: x.num_pc/cmnty_len[x.cmnty], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    #groupby user now To populate a dictionary for each user.\n",
    "    grp=df.groupby(['cmnty'])\n",
    "\n",
    "    feature_cmnty_dic={} #user:df with feature value\n",
    "    #iterating groups\n",
    "    for name, group in grp:\n",
    "        # print (name)\n",
    "        # print (group)\n",
    "        feature_cmnty_dic[name]=group\n",
    "        # ldf = group.groupby(['date'], as_index=False)['cntr'].size()\n",
    "\n",
    "\n",
    "\n",
    "    return feature_cmnty_dic\n",
    "\n",
    "def prep_pbp_dic(df):\n",
    "    #convert date column of srt type to Timestamp type.\n",
    "    df['date'] = df['date'].apply(dateutil.parser.parse, dayfirst=False)\n",
    "    #now convert date column of Timestamptype to only date values and remove hr:mm:ss\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    # create user, date wise groups and count unique dates then add a separate column for the counts\n",
    "    df=df.groupby(['peer', 'date']).pc.agg('nunique').to_frame('num_pc').reset_index()\n",
    "\n",
    "    cmnty_len = Counter(usr_peer_map.values())\n",
    "    #make values of email freq avg of community\n",
    "    df['num_pc'] = df.apply( lambda x: x.num_pc/cmnty_len[x.peer], axis=1)\n",
    "\n",
    "    #groupby user now To populate a dictionary for each user.\n",
    "    grp=df.groupby(['peer'])\n",
    "\n",
    "    feature_peer_dic={} #user:df with feature value\n",
    "    #iterating groups\n",
    "    for name, group in grp:\n",
    "        # print (name)\n",
    "        # print (group)\n",
    "        feature_peer_dic[name]=group\n",
    "        # ldf = group.groupby(['date'], as_index=False)['cntr'].size()\n",
    "    return feature_peer_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubp_dev_act_feature_df = dev_act_feature_df.copy()\n",
    "ubp_dev_act_feature_dic = prep_ubp_dic(ubp_dev_act_feature_df)\n",
    "\n",
    "\n",
    "cbp_dev_act_feature_df = dev_act_feature_cmnty_df.copy()\n",
    "cbp_dev_act_feature_dic = prep_cbp_dic(cbp_dev_act_feature_df)\n",
    "\n",
    "\n",
    "pbp_dev_act_feature_df = dev_act_feature_peer_df.copy()\n",
    "pbp_dev_act_feature_dic = prep_pbp_dic(pbp_dev_act_feature_df)\n",
    "\n",
    "pickle_store(\"pickle/f11/f11_ubp_file\", ubp_dev_act_feature_dic)\n",
    "pickle_store(\"pickle/f11/f11_pbp_file\", pbp_dev_act_feature_dic)\n",
    "pickle_store(\"pickle/f11/f11_cbp_file\", cbp_dev_act_feature_dic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adem import *\n",
    "count = 0\n",
    "feature_name = 'num_pc'\n",
    "\n",
    "print(\"PBP\")\n",
    "\n",
    "for key in ubp_dev_act_feature_dic:\n",
    "    usr=key #'AAM0658'\n",
    "    debug_df = ubp_dev_act_feature_dic[usr]\n",
    "    debug_peer_df = pbp_dev_act_feature_dic[usr_peer_map[usr]]\n",
    "\n",
    "    #do a depp copy of preped feature dataframe\n",
    "    df = debug_df.copy()\n",
    "    df_peer = debug_peer_df.copy()\n",
    "    \n",
    "    uname = key\n",
    "    print(key)\n",
    "    anom_calc_pbp(df, df_peer, feature_name, uname, ws=10, sig=3)\n",
    "    \n",
    "    count += 1\n",
    "    if count%10 == 0:\n",
    "        break\n",
    "\n",
    "print(\"CBP\")\n",
    "\n",
    "for key in ubp_dev_act_feature_dic:\n",
    "    usr=key\n",
    "    debug_df = ubp_dev_act_feature_dic[usr]\n",
    "    debug_cmnty_df = cbp_dev_act_feature_dic[usr_cmnty_map[usr]]\n",
    "\n",
    "    #do a depp copy of preped feature dataframe\n",
    "    df = debug_df.copy()\n",
    "    df_cmnty = debug_cmnty_df.copy()\n",
    "\n",
    "    uname = key\n",
    "    print(key)\n",
    "    anom_calc_cbp(df, df_cmnty, feature_name, uname, ws=10, sig=3)\n",
    "    \n",
    "    count += 1\n",
    "    if count%10 == 0:\n",
    "        break\n",
    "\n",
    "print(\"UBP\")\n",
    "\n",
    "# email_freq_feature_dic.keys()\n",
    "# Feature data format:  user: df [user, date, featurecolmn]\n",
    "for key in ubp_dev_act_feature_dic:\n",
    "    usr=key\n",
    "    debug_df = ubp_dev_act_feature_dic[usr]\n",
    "\n",
    "\n",
    "    #do a depp copy of preped feature dataframe\n",
    "    df = debug_df.copy()\n",
    "    print(key)\n",
    "    anom_calc_ubp(df, feature_name, usr, ws=10, sig=3)\n",
    "    \n",
    "    # count += 1\n",
    "    # if count%10 == 0:\n",
    "    #     break"
   ]
  }
 ]
}